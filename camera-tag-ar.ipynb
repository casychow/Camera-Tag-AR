{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2 Math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1219, -2918], [-2131, 3]]\n",
      "[-9895595, -3530590]\n",
      "1660.5736987728053 2697.5173616161583\n",
      "983.7005811985779\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Define the origin and three vanishing points that were manually detected\n",
    "origin = (1318, 1990)\n",
    "u1,v1=(1657,159)\n",
    "u2,v2=(745,3080)\n",
    "u3,v3=(2876,3077)\n",
    "\n",
    "# Compute A and b matrix\n",
    "A=[[u1-u3, v1-v3],[u2-u3, v2-v3]]\n",
    "b=[((u1-u3)*u2 + (v1-v3)*v2), ((u2-u3)*u1 + (v2-v3)*v1)]\n",
    "print(A)\n",
    "print(b)\n",
    "\n",
    "# Solve \"Ax=b\"\n",
    "x=np.linalg.lstsq(A,b)\n",
    "print(x)\n",
    "\n",
    "# Find principle point\n",
    "x0, y0 = np.dot(np.linalg.inv(A), b)\n",
    "print(x0, y0)\n",
    "\n",
    "# Find focal point\n",
    "focal_point = math.sqrt(-(u1-x0)*(u2-x0)-(v1-y0)*(v2-y0))\n",
    "print(focal_point)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "import cv2.aruco as aruco\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "aruco_dict = aruco.Dictionary_get(aruco.DICT_6X6_1000)\n",
    "\n",
    "# Dimensions in cm\n",
    "marker_length = 3.7\n",
    "marker_separation = 1.1\n",
    "aruco_params = aruco.DetectorParameters_create()\n",
    "board = aruco.GridBoard_create(5,7,marker_length,marker_separation,aruco_dict)\n",
    "imboard = board.draw((2000,2000))\n",
    "cv2.imwrite(\"chessboard.png\", imboard)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "plt.imshow(imboard, interpolation=\"nearest\")\n",
    "ax.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter, corners_list, id_list = [],[],[]\n",
    "first = 0\n",
    "folder = \"calibration_pics\"\n",
    "\n",
    "# Find aruco markers inside each image\n",
    "for filename in os.listdir(folder):\n",
    "    img = cv2.imread(os.path.join(folder, filename))\n",
    "    if img is not None:\n",
    "        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        corners, ids, rejected = aruco.detectMarkers(\n",
    "            img_gray,\n",
    "            aruco_dict,\n",
    "            parameters=aruco_params\n",
    "        )\n",
    "    if first:\n",
    "        corners_list = np.vstack((corners_list, corners))\n",
    "        id_list=np.vstack((id_list,ids))\n",
    "    else:\n",
    "        corners_list=corners\n",
    "        id_list=ids\n",
    "    first+=1\n",
    "    counter.append(len(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = np.array(counter)\n",
    "ret, mtx, dist, rvecs,tvecs = aruco.calibrateCameraAruco(\n",
    "    corners_list,\n",
    "    id_list,\n",
    "    counter,\n",
    "    board,\n",
    "    img_gray.shape,\n",
    "    None,\n",
    "    None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.79809819e+03, 0.00000000e+00, 1.02532172e+03],\n",
       "       [0.00000000e+00, 5.72315054e+03, 1.24298224e+03],\n",
       "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.52683115, -13.31615208,  -0.16441339,  -0.01637706,\n",
       "         14.82210046]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 4\n",
    "\n",
    "Use the pyAprilTag package to detect an AprilTag in an image (or use OpenCV for an Aruco Tag), for which you should take a photo of a tag. Use the K matrix you obtained above, to draw a 3D cube of the same size of the tag on the image, as if this virtual cube really is on top of the tag. Document the methods you use, and show your AR results from at least two different perspectives.\n",
    "\n",
    "\n",
    "OpenCV's projectPoints, drawContours, addWeighted and line methods useful. You don't have to use all these methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Aruco variables\n",
    "aruco_dict = aruco.Dictionary_get(aruco.DICT_6X6_250)\n",
    "aruco_params = aruco.DetectorParameters_create()\n",
    "\n",
    "# Still using previous board and imboard variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.0375  0.0375  0.    ]]\n",
      "\n",
      " [[ 0.0375  0.0375  0.    ]]\n",
      "\n",
      " [[ 0.0375 -0.0375  0.    ]]\n",
      "\n",
      " [[-0.0375 -0.0375  0.    ]]]\n",
      "[[-0.0375  0.0375  0.08  ]\n",
      " [ 0.0375  0.0375  0.08  ]\n",
      " [ 0.0375 -0.0375  0.08  ]\n",
      " [-0.0375 -0.0375  0.08  ]\n",
      " [-0.0375  0.0375  0.    ]\n",
      " [ 0.0375  0.0375  0.    ]\n",
      " [ 0.0375 -0.0375  0.    ]\n",
      " [-0.0375 -0.0375  0.    ]]\n",
      "[[[-0.0375  0.0375  0.    ]]\n",
      "\n",
      " [[ 0.0375  0.0375  0.    ]]\n",
      "\n",
      " [[ 0.0375 -0.0375  0.    ]]\n",
      "\n",
      " [[-0.0375 -0.0375  0.    ]]]\n",
      "[[-0.0375  0.0375  0.08  ]\n",
      " [ 0.0375  0.0375  0.08  ]\n",
      " [ 0.0375 -0.0375  0.08  ]\n",
      " [-0.0375 -0.0375  0.08  ]\n",
      " [-0.0375  0.0375  0.    ]\n",
      " [ 0.0375  0.0375  0.    ]\n",
      " [ 0.0375 -0.0375  0.    ]\n",
      " [-0.0375 -0.0375  0.    ]]\n",
      "[[[-0.0375  0.0375  0.    ]]\n",
      "\n",
      " [[ 0.0375  0.0375  0.    ]]\n",
      "\n",
      " [[ 0.0375 -0.0375  0.    ]]\n",
      "\n",
      " [[-0.0375 -0.0375  0.    ]]]\n",
      "[[-0.0375  0.0375  0.08  ]\n",
      " [ 0.0375  0.0375  0.08  ]\n",
      " [ 0.0375 -0.0375  0.08  ]\n",
      " [-0.0375 -0.0375  0.08  ]\n",
      " [-0.0375  0.0375  0.    ]\n",
      " [ 0.0375  0.0375  0.    ]\n",
      " [ 0.0375 -0.0375  0.    ]\n",
      " [-0.0375 -0.0375  0.    ]]\n",
      "[[[-0.0375  0.0375  0.    ]]\n",
      "\n",
      " [[ 0.0375  0.0375  0.    ]]\n",
      "\n",
      " [[ 0.0375 -0.0375  0.    ]]\n",
      "\n",
      " [[-0.0375 -0.0375  0.    ]]]\n",
      "[[-0.0375  0.0375  0.08  ]\n",
      " [ 0.0375  0.0375  0.08  ]\n",
      " [ 0.0375 -0.0375  0.08  ]\n",
      " [-0.0375 -0.0375  0.08  ]\n",
      " [-0.0375  0.0375  0.    ]\n",
      " [ 0.0375  0.0375  0.    ]\n",
      " [ 0.0375 -0.0375  0.    ]\n",
      " [-0.0375 -0.0375  0.    ]]\n"
     ]
    }
   ],
   "source": [
    "# Load pictures from folder - will save finished pictures in current working directory\n",
    "folder = os.path.join(os.getcwd(), \"q4\")\n",
    "\n",
    "# Color coordinates\n",
    "color = (0, 0, 255) # Red\n",
    "line_thickness = 20\n",
    "projection_z = 0.075 # How much to project cube upwards from aruco tag face\n",
    "\n",
    "# Find aruco markers inside each image\n",
    "for filename in os.listdir(folder):\n",
    "    # Reset the variables for another file\n",
    "    rvecs, tvecs, object_points = 0,0,0\n",
    "    # This argument sometimes appears when looking for image files - remove file\n",
    "    if (filename != \".DS_Store\"): \n",
    "        img = cv2.imread(os.path.join(folder, filename))\n",
    "        if img is not None:\n",
    "            corners, ids, rejected = aruco.detectMarkers(\n",
    "                img,\n",
    "                aruco_dict,\n",
    "                parameters=aruco_params\n",
    "            )\n",
    "\n",
    "            # estimatePoseSingleMarkers takes in 1) array of array of corners, 2) markerLength (use ruler, unit in m),\n",
    "            #                                    3) cameraMatrix, and 4) distantCoefficients (from question 3)\n",
    "            # estimatePoseSingleMarkers returns 1) rotation matrix, 2) translation matrix, 3) objectPoints\n",
    "            rvecs, tvecs, object_points = aruco.estimatePoseSingleMarkers(corners, 0.075, mtx, dist)\n",
    "            #print(object_points)\n",
    "            new_object_points = np.copy(object_points)\n",
    "            new_object_points = np.append(new_object_points, object_points)\n",
    "            new_object_points = np.reshape(new_object_points, (8,3)) #reshape nparray to 8 rows of 3 columns of values\n",
    "\n",
    "            # Edit the first four arrays in new_object_points s.t. the last index is z\n",
    "            for ind, array in enumerate(new_object_points):\n",
    "                if (ind < len(new_object_points)/2):\n",
    "                    array[2] = projection_z\n",
    "            # First half of new_object_points will have a z value of projection_z\n",
    "            # The latter half will have a z value of 0\n",
    "\n",
    "            #print(new_object_points)\n",
    "\n",
    "            image_points, jacobian = cv2.projectPoints(new_object_points, rvecs, tvecs, mtx, dist)\n",
    "\n",
    "            # Flatten image_points to easily pack values together with .reshape()\n",
    "            image_points = np.ndarray.flatten(image_points)\n",
    "            new_image_points = []\n",
    "            for num in image_points:\n",
    "                new_image_points.append(int(abs(num))) # Some of the values are negative\n",
    "            new_image_points = np.reshape(new_image_points, (8,2))\n",
    "\n",
    "            # Now join all the lines\n",
    "            # Points 0-3: upper box\n",
    "            # Points 4-7: lower box\n",
    "            point0 = new_image_points[0]\n",
    "            point1 = new_image_points[1]\n",
    "            point2 = new_image_points[2]\n",
    "            point3 = new_image_points[3]\n",
    "            point4 = new_image_points[4]\n",
    "            point5 = new_image_points[5]\n",
    "            point6 = new_image_points[6]\n",
    "            point7 = new_image_points[7]\n",
    "\n",
    "            # Draw lines around upper box\n",
    "            cv2.line(img, point0, point1, color, line_thickness)\n",
    "            cv2.line(img, point1, point2, color, line_thickness)\n",
    "            cv2.line(img, point2, point3, color, line_thickness)\n",
    "            cv2.line(img, point3, point0, color, line_thickness)\n",
    "\n",
    "            # Draw lines around lower box\n",
    "            cv2.line(img, point4, point5, color, line_thickness)\n",
    "            cv2.line(img, point5, point6, color, line_thickness)\n",
    "            cv2.line(img, point6, point7, color, line_thickness)\n",
    "            cv2.line(img, point7, point4, color, line_thickness)\n",
    "\n",
    "            # Draw lines connecting lower and upper boxes\n",
    "            cv2.line(img, point4, point0, color, line_thickness)\n",
    "            cv2.line(img, point5, point1, color, line_thickness)\n",
    "            cv2.line(img, point6, point2, color, line_thickness)\n",
    "            cv2.line(img, point7, point3, color, line_thickness)\n",
    "\n",
    "            # Write to image\n",
    "            cv2.imwrite(filename, img=img)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('myenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "80abf3a9fb5314e6019b88c3f2d8ecbd4207c1759cf81fd7623ca63a92b968a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
